{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    "dataDir = Path('../dataset/images') \n",
    "annotationsDir = Path('../dataset/annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating expected dataframes\n",
    "\n",
    "def filelist(root, file_type):\n",
    "    return [os.path.join(directory_path, f) for directory_path, directory_name, \n",
    "            files in os.walk(root) for f in files if f.endswith(file_type)]\n",
    "\n",
    "def generate_train_multiple (anno_path): # Creates a dataframe with all images\n",
    "    annotations = filelist(anno_path, '.xml')\n",
    "    anno_list = []\n",
    "    for anno_path in annotations:\n",
    "        root = ET.parse(anno_path).getroot()\n",
    "        anno = {}\n",
    "        anno['filename'] = str(dataDir) + '/'+ root.find(\"./filename\").text\n",
    "        classArray = []\n",
    "        for child in root:\n",
    "            if child.tag == \"object\":\n",
    "                for grandchild in child:\n",
    "                    if grandchild.tag == \"name\":\n",
    "                        if grandchild.text != \"trafficlight\":\n",
    "                            classArray.append(grandchild.text)\n",
    "        anno['expected'] = classArray\n",
    "        if len(classArray) != 0:\n",
    "            anno_list.append(anno)\n",
    "            \n",
    "    return pd.DataFrame(anno_list)\n",
    "\n",
    "def generate_train_single (anno_path): # Creates a dataframe only with images that have a single roadsign to detect\n",
    "    annotations = filelist(anno_path, '.xml')\n",
    "    anno_list = []\n",
    "    for anno_path in annotations:\n",
    "        root = ET.parse(anno_path).getroot()\n",
    "        anno = {}\n",
    "        anno['filename'] = str(dataDir) + '/'+ root.find(\"./filename\").text\n",
    "        classArray = []\n",
    "        for child in root:\n",
    "            if child.tag == \"object\":\n",
    "                for grandchild in child:\n",
    "                    if grandchild.tag == \"name\":\n",
    "                        if grandchild.text != \"trafficlight\":\n",
    "                            classArray.append(grandchild.text)\n",
    "        anno['expected'] = classArray\n",
    "        if len(classArray) == 1:\n",
    "            anno_list.append(anno)\n",
    "            \n",
    "    return pd.DataFrame(anno_list)\n",
    "\n",
    "def generate_train_simple (anno_path): # Creates a dataframe with the first 170 images\n",
    "    annotations = filelist(anno_path, '.xml')\n",
    "    anno_list = []\n",
    "    for anno_path in annotations:\n",
    "        root = ET.parse(anno_path).getroot()\n",
    "        anno = {}\n",
    "        anno['filename'] = str(dataDir) + '/'+ root.find(\"./filename\").text\n",
    "        for child in root:\n",
    "            if child.tag == \"object\":\n",
    "                for grandchild in child:\n",
    "                    if grandchild.tag == \"name\":\n",
    "                        anno['expected'] = grandchild.text\n",
    "        if int(anno['filename'][22:len(anno['filename'])-4]) < 170:\n",
    "            anno_list.append(anno)\n",
    "        \n",
    "    return pd.DataFrame(anno_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Pre-processing\n",
    "\n",
    "# Improve Lighting\n",
    "\n",
    "def improve_lighting(img):\n",
    "    imgYUV = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    imgYUV[:, :, 0] = cv2.equalizeHist(imgYUV[:, :, 0])\n",
    "\n",
    "    imgBetterLighting = cv2.cvtColor(imgYUV, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "    imgHSV = cv2.cvtColor(imgBetterLighting, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(imgHSV)\n",
    "\n",
    "    lim = 255 - 50\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += 50\n",
    "\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    imgBetterLighting = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return imgBetterLighting\n",
    "\n",
    "# Smoothing\n",
    "\n",
    "def image_smooth(img):\n",
    "    imgWithMedianFilter = cv2.medianBlur(img, 5)\n",
    "\n",
    "    return imgWithMedianFilter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Segmentation by color\n",
    "\n",
    "def image_segmentation(img):\n",
    "    #set the bounds for the red hue\n",
    "    lower_red_n1 = np.array([0,70,60])\n",
    "    upper_red_n1 = np.array([10,255,255])\n",
    "\n",
    "    lower_red_n2 = np.array([170,70,60])\n",
    "    upper_red_n2 = np.array([180,255,255])\n",
    "\n",
    "    lower_blue_n3 = np.array([78,158,124])\n",
    "    upper_blue_n3 = np.array([138,255,255])\n",
    "\n",
    "    #create a mask using the bounds set\n",
    "\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "    mask_1 = cv2.inRange(img_hsv, lower_red_n1, upper_red_n1)\n",
    "    mask_2 = cv2.inRange(img_hsv, lower_red_n2, upper_red_n2)\n",
    "\n",
    "    mask_red = mask_1 + mask_2\n",
    "\n",
    "    mask_blue = cv2.inRange(img_hsv, lower_blue_n3, upper_blue_n3)\n",
    "\n",
    "    return mask_blue, mask_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Thresholding and Morphological Operations\n",
    "\n",
    "def morphological_ops(img):\n",
    "    # Red\n",
    "\n",
    "    # Removing Noise\n",
    "    kernel = np.ones((3, 3),np.uint8)\n",
    "    processed_red = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel, iterations = 1)\n",
    "    processed_red = cv2.morphologyEx(processed_red, cv2.MORPH_DILATE, kernel, iterations = 1)\n",
    "\n",
    "    # Floodfill\n",
    "\n",
    "    red_floodfill = processed_red.copy()\n",
    "\n",
    "    h, w = processed_red.shape[:2]\n",
    "\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "    cv2.floodFill(red_floodfill, mask, (0,0), 255)\n",
    "\n",
    "    red_floodfill_inv = cv2.bitwise_not(red_floodfill)\n",
    "\n",
    "    filled_image = processed_red | red_floodfill_inv\n",
    "\n",
    "    return filled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape Recognition\n",
    "\n",
    "def shape_recognition(img_red, img_blue, initial_image):\n",
    "    \n",
    "    result = \"\"\n",
    "    results = []\n",
    "    img_red_contours = initial_image\n",
    "    img_blue_contours = initial_image\n",
    "\n",
    "    # Red\n",
    "    debug = \"red\"\n",
    "\n",
    "    # Octagon Detection\n",
    "    contours_red, hierarchy_red = cv2.findContours(img_red, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    maxArea = 0\n",
    "\n",
    "    for cnt in contours_red:\n",
    "        approx = cv2.approxPolyDP(cnt, 0.01*cv2.arcLength(cnt, True), True)\n",
    "\n",
    "        if len(approx) == 8:\n",
    "            cntArea = cv2.contourArea(cnt)\n",
    "            if cntArea > maxArea:\n",
    "                maxArea = cntArea\n",
    "                maxContour = cnt\n",
    "                result = \"stop\"\n",
    "\n",
    "            results.append(\"stop\")\n",
    "            img_red_contours = cv2.drawContours(initial_image, [cnt], 0, (0,0,255), -1)\n",
    "\n",
    "        elif len(approx) >= 12:\n",
    "            cntArea = cv2.contourArea(cnt)\n",
    "            if cntArea > maxArea:\n",
    "                maxArea = cntArea\n",
    "                maxContour = cnt\n",
    "                result = \"speedlimit\"\n",
    "         \n",
    "            results.append(\"speedlimit\")\n",
    "            img_red_contours = cv2.drawContours(initial_image, [cnt], 0, (0,0,255), -1)\n",
    "\n",
    "    # Blue\n",
    "\n",
    "    contours_blue, hierarchy_blue = cv2.findContours(img_blue, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for cnt in contours_blue:\n",
    "        approx = cv2.approxPolyDP(cnt, 0.01*cv2.arcLength(cnt, True), True)\n",
    "\n",
    "        if len(approx) == 4:\n",
    "            cntArea = cv2.contourArea(cnt)\n",
    "            if cntArea > maxArea:\n",
    "                maxArea = cntArea\n",
    "                maxContour = cnt\n",
    "                result = \"crosswalk\"\n",
    "        \n",
    "            results.append(\"crosswalk\")\n",
    "            # debug = \"blue\"\n",
    "            img_blue_contours = cv2.drawContours(initial_image, [maxContour], 0, (255,0,0), -1)\n",
    "\n",
    "    \n",
    "    # if debug==\"red\":\n",
    "        # plt.imshow(cv2.cvtColor(img_red_contours, cv2.COLOR_BGR2RGB))\n",
    "        # plt.title('Foreground')\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "    # elif debug == \"blue\":\n",
    "        # plt.imshow(cv2.cvtColor(img_blue_contours, cv2.COLOR_BGR2RGB))\n",
    "        # plt.title('Foreground')\n",
    "        # plt.axis('off')\n",
    "        # plt.show() \n",
    "    \n",
    "    \n",
    "    return result, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the roadsigns in a certain image\n",
    "\n",
    "def evaluate_image(imgPath):\n",
    "    \n",
    "    img = cv2.imread(imgPath)\n",
    "\n",
    "    imgLighting = improve_lighting(img)\n",
    "    imgSmooth = image_smooth(imgLighting)\n",
    "    img_blue, img_red = image_segmentation(imgSmooth)\n",
    "    processed_blue = morphological_ops(img_blue)\n",
    "    processed_red = morphological_ops(img_red)\n",
    "    result = shape_recognition(processed_red, processed_blue, img)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating prediction Dataframe\n",
    "\n",
    "def generate_prediction_multiple(df_compare): # Creates a dataframe with all the detected signs  \n",
    "    pred_list = []                            # in the images from a given dataframe\n",
    "    for index, row in df_compare.iterrows():\n",
    "        pred = {}\n",
    "        pred[\"filename\"] = row[\"filename\"]\n",
    "        result, results = evaluate_image(row[\"filename\"])\n",
    "        pred[\"prediction\"] = results\n",
    "        pred_list.append(pred)\n",
    "    return pd.DataFrame(pred_list)\n",
    "\n",
    "def generate_prediction_single(df_compare): # Creates a dataframe with the single sign detected\n",
    "    pred_list = []                          # in the images from a given dataframe\n",
    "    for index, row in df_compare.iterrows():\n",
    "        pred = {}\n",
    "        pred[\"filename\"] = row[\"filename\"]\n",
    "        result, results = evaluate_image(row[\"filename\"])\n",
    "        pred[\"prediction\"] = result\n",
    "        pred_list.append(pred)\n",
    "    return pd.DataFrame(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes\n",
    "\n",
    "def join_dataframes(df_train, df_pred): # Merges the dataframe with the expected results \n",
    "                                        # with the dataframe of the signs detected by our algorithm, \n",
    "                                        # adding a column that reflects the similarity between the two\n",
    "    df_merged = pd.merge(df_train, df_pred, on='filename')\n",
    "\n",
    "    for index, row in df_merged.iterrows():\n",
    "        sm = difflib.SequenceMatcher(None,row[\"expected\"],row[\"prediction\"])\n",
    "        df_merged.at[index,\"Similarity\"] = sm.ratio()\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def join_dataframes_simple(df_train, df_pred):  # Merges the dataframe with the expected result \n",
    "                                                # with the dataframe of the sign detected by our algorithm, \n",
    "                                                # adding a column that reflects the similarity between the two\n",
    "    df_merged = pd.merge(df_train, df_pred, on='filename')\n",
    "\n",
    "    for index, row in df_merged.iterrows():\n",
    "        sm = difflib.SequenceMatcher(None,row[\"expected\"],row[\"prediction\"])\n",
    "        if sm.ratio() == 0:\n",
    "            df_merged.at[index,\"Similarity\"] = 1\n",
    "        elif sm.ratio() == 1:\n",
    "            df_merged.at[index,\"Similarity\"] = 1\n",
    "        else:\n",
    "            df_merged.at[index,\"Similarity\"] = 0\n",
    "\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for simple images: 53.529411764705884 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>expected</th>\n",
       "      <th>prediction</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../dataset/images/road18.png</td>\n",
       "      <td>trafficlight</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../dataset/images/road128.png</td>\n",
       "      <td>crosswalk</td>\n",
       "      <td>speedlimit</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../dataset/images/road100.png</td>\n",
       "      <td>speedlimit</td>\n",
       "      <td>speedlimit</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../dataset/images/road24.png</td>\n",
       "      <td>trafficlight</td>\n",
       "      <td>speedlimit</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../dataset/images/road30.png</td>\n",
       "      <td>trafficlight</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename      expected  prediction  Similarity\n",
       "0   ../dataset/images/road18.png  trafficlight                     1.0\n",
       "1  ../dataset/images/road128.png     crosswalk  speedlimit         0.0\n",
       "2  ../dataset/images/road100.png    speedlimit  speedlimit         1.0\n",
       "3   ../dataset/images/road24.png  trafficlight  speedlimit         0.0\n",
       "4   ../dataset/images/road30.png  trafficlight                     1.0"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance evaluation - Simple Images\n",
    "\n",
    "# Evaluates the performance of our sign detection algorithm within the first 170 images,\n",
    "# that are well illuminated. Included the trafficlight images to demonstrate the non \n",
    "# detection of false positives\n",
    "\n",
    "df_compare = generate_train_simple(annotationsDir)\n",
    "df_pred = generate_prediction_single(df_compare)\n",
    "\n",
    "df_simple = generate_train_simple(annotationsDir)\n",
    "df_merged = join_dataframes_simple(df_simple, df_pred)\n",
    "print(\"Performance for simple images: \" + str(df_merged[\"Similarity\"].mean()*100) + \" %\")\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for simple images: 27.418667204263198 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>expected</th>\n",
       "      <th>prediction</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../dataset/images/road289.png</td>\n",
       "      <td>[stop]</td>\n",
       "      <td>[speedlimit, crosswalk, crosswalk, crosswalk, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../dataset/images/road538.png</td>\n",
       "      <td>[speedlimit]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../dataset/images/road510.png</td>\n",
       "      <td>[speedlimit]</td>\n",
       "      <td>[speedlimit]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../dataset/images/road276.png</td>\n",
       "      <td>[speedlimit]</td>\n",
       "      <td>[crosswalk, crosswalk]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../dataset/images/road262.png</td>\n",
       "      <td>[speedlimit]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename      expected  \\\n",
       "0  ../dataset/images/road289.png        [stop]   \n",
       "1  ../dataset/images/road538.png  [speedlimit]   \n",
       "2  ../dataset/images/road510.png  [speedlimit]   \n",
       "3  ../dataset/images/road276.png  [speedlimit]   \n",
       "4  ../dataset/images/road262.png  [speedlimit]   \n",
       "\n",
       "                                          prediction  Similarity  \n",
       "0  [speedlimit, crosswalk, crosswalk, crosswalk, ...         0.0  \n",
       "1                                                 []         0.0  \n",
       "2                                       [speedlimit]         1.0  \n",
       "3                             [crosswalk, crosswalk]         0.0  \n",
       "4                                                 []         0.0  "
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance evaluation - One sign Images\n",
    "\n",
    "# Evaluates the performance of our sign detection algorithm for images with only 1 sign \n",
    "# expected to be detected in the image\n",
    "\n",
    "df_compare = generate_train_single(annotationsDir)\n",
    "df_pred = generate_prediction_multiple(df_compare)\n",
    "\n",
    "df_single = generate_train_single(annotationsDir)\n",
    "df_merged = join_dataframes(df_single, df_pred)\n",
    "print(\"Performance for simple images: \" + str(df_merged[\"Similarity\"].mean()*100) + \" %\")\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for simple images: 28.13665654014769 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>expected</th>\n",
       "      <th>prediction</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../dataset/images/road712.png</td>\n",
       "      <td>[speedlimit, speedlimit]</td>\n",
       "      <td>[speedlimit, stop, speedlimit, speedlimit]</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../dataset/images/road706.png</td>\n",
       "      <td>[speedlimit, speedlimit]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../dataset/images/road289.png</td>\n",
       "      <td>[stop]</td>\n",
       "      <td>[speedlimit, crosswalk, crosswalk, crosswalk, ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../dataset/images/road538.png</td>\n",
       "      <td>[speedlimit]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../dataset/images/road510.png</td>\n",
       "      <td>[speedlimit]</td>\n",
       "      <td>[speedlimit]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename                  expected  \\\n",
       "0  ../dataset/images/road712.png  [speedlimit, speedlimit]   \n",
       "1  ../dataset/images/road706.png  [speedlimit, speedlimit]   \n",
       "2  ../dataset/images/road289.png                    [stop]   \n",
       "3  ../dataset/images/road538.png              [speedlimit]   \n",
       "4  ../dataset/images/road510.png              [speedlimit]   \n",
       "\n",
       "                                          prediction  Similarity  \n",
       "0         [speedlimit, stop, speedlimit, speedlimit]    0.666667  \n",
       "1                                                 []    0.000000  \n",
       "2  [speedlimit, crosswalk, crosswalk, crosswalk, ...    0.000000  \n",
       "3                                                 []    0.000000  \n",
       "4                                       [speedlimit]    1.000000  "
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance evaluation - Multiple sign Images\n",
    "\n",
    "# Evaluates the performance of our sign detection algorithm for all the images in the dataset\n",
    "\n",
    "df_compare = generate_train_multiple(annotationsDir)\n",
    "df_pred = generate_prediction_multiple(df_compare)\n",
    "\n",
    "df_multiple = generate_train_multiple(annotationsDir)\n",
    "df_merged = join_dataframes(df_multiple, df_pred)\n",
    "print(\"Performance for simple images: \" + str(df_merged[\"Similarity\"].mean()*100) + \" %\")\n",
    "df_merged.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
